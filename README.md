# *Задание 1 Работа с Yandex Data Proc и Hive/Spark*
*1. Поднят кластер Yandex Data Proc (Hadoop + Hive/Spark)*
*2. Созданы две таблицы при помощи Hive или PySpark*
* transactions_v2
* logs_v2
*3. Заполнены таблицы данными их TXT и CSV файлов (они размещены в Object Storage)*
*4. Выполнено несколько различных агрегаций на основе созданных таблиц:*
* фильтрация хороших валют (USD, EUR, RUB), подсчет суммарной суммы транзакций по каждой валюте
* подсчет количества мошеннических (is_fraud = 1) и нормальных (is_fraud = 0) транзакций, суммарной суммы и среднего чека
* группировка по датам и вычислениям ежедневного количества транзакций, суммарного объема и среднего *amount*
* использование временных функций (например, извлечение дня/месяца из *transaction_date*) и анализ транзакций по временным интервалам
* join с таблицей logs_v2 по transaction_id, чтобы подсчитать количество логов на одну транзакицию, выделить самые частые категории и т.д.
# *задание 2 Работа с ClickHouse*
*1. Поднята систему ClickHouse*
*2. Созданы таблицы:*
* orders
* order_items
*3. Заполнены данными из TXT и CSV файлов (они размещены в Object Storage)*
*4. Выполнено несколько агрегаций на основе созданных таблиц:*
* группировка по payment_status: подсчитываем количество заказов, сумму (total_amount), среднюю стоимость заказа
* join с order_items: подсчитать общее количество товаров, общую сумму, среднюю цену за продукт
* статистика по датам (количество заказов и их суммарная стоимость за каждый день)
* выделение "самых активных" пользователей (по сумме или по количеству заказов)
# *Задание 3 Визуалмзация в DataLens*
*С помощью Yandex DataLens построены дашборды:*
* динамика суммарных транзакций по датам
* диаграмма по распределению валют
* диаграмма по количеству заказов
* настроены фильтры (отбор по датам, пользователям, статусам)
# *Задание 4 Реплика данных*
*Настроена репликация данных из DataProc (Hive/Spark) в ClickHouse при помощи Airflow:*
* создан DAG, который периодически или по запросу выгружает результаты из Hive (или HDFS) и загружаны в ClickHouse
* DAG корректно отрабатывает и данные появляются в нужной таблице ClickHouse
